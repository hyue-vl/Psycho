{
  "llm": {
    "provider": "openai",
    "model": "gpt-4o-mini",
    "temperature": 0.2,
    "max_output_tokens": 1024,
    "base_url": "https://api.openai.com/v1",
    "api_key": "sk-your-key"
  },
  "knowledge_base": {
    "coke_json_path": "./data/coke.json",
    "chroma_dir": "./data/coke_db",
    "neo4j_uri": "bolt://localhost:7687",
    "neo4j_user": "neo4j",
    "neo4j_password": "please-change-me",
    "memgpt_api_key": "memgpt-your-key"
  },
  "annotation": {
    "dataset_name": "psyqa-esconv",
    "max_turns": 12,
    "teacher_model": "gpt-4o-mini",
    "temperature": 0.2,
    "batch_size": 4,
    "save_dir": "./data/processed",
    "prompt_template": "./psycho_world/prompts/cognitive.py"
  },
  "training": {
    "model_name": "Qwen/Qwen2-7B-Instruct",
    "learning_rate": 2e-5,
    "weight_decay": 0.01,
    "warmup_ratio": 0.05,
    "gradient_accumulation": 2,
    "max_steps": 20000,
    "save_steps": 1000,
    "log_steps": 50,
    "output_dir": "./artifacts",
    "use_lora": true,
    "lora_r": 16,
    "lora_alpha": 32,
    "lora_dropout": 0.05
  },
  "dreaming": {
    "rollout_horizon": 3,
    "num_simulations": 20,
    "branching_factor": 4,
    "gamma": 0.95,
    "ucb_exploration": 1.4,
    "reward_shaping_weights": [1.0, -5.0, 0.3]
  }
}
